# ç¦ç”¨æ—¥å¿—è¾“å‡º
import logging
import os
logging.getLogger().setLevel(logging.CRITICAL)
os.environ['LOGURU_LEVEL'] = 'CRITICAL'
# ç¦ç”¨loguruæ—¥å¿—æ–‡ä»¶è¾“å‡º
os.environ['LOGURU_DISABLE'] = 'True'

import argparse
import asyncio
import pandas as pd
from pathlib import Path
import re
import json

from Core.Common.LLM import LLM


def check_sft_format_detailed(answer: str) -> tuple[bool, str]:
    """æ£€æŸ¥SFTè¾“å‡ºæ ¼å¼å¹¶è¿”å›è¯¦ç»†é”™è¯¯ä¿¡æ¯
    
    æ”¯æŒä¸¤ç§æ ¼å¼ï¼š
    1. ableæ ¼å¼: <think>...</think><label>able</label><answer>...</answer>
    2. unableæ ¼å¼: <think>...</think><label>unable</label><query>...</query>
    """
    answer = answer.strip()
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«å¿…éœ€çš„<think>æ ‡ç­¾
    think_match = re.search(r'<think>(.*?)</think>', answer, re.DOTALL)
    if not think_match:
        return False, "ç¼ºå°‘<think>æ ‡ç­¾"
    
    # æ£€æŸ¥thinkæ ‡ç­¾æ˜¯å¦ä¸ºç©º
    think_content = think_match.group(1).strip()
    if not think_content:
        return False, "thinkæ ‡ç­¾ä¸ºç©º"
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«<label>æ ‡ç­¾
    label_match = re.search(r'<label>\s*(able|unable)\s*</label>', answer, re.DOTALL)
    if not label_match:
        return False, "ç¼ºå°‘<label>æ ‡ç­¾æˆ–æ ‡ç­¾å€¼ä¸æ˜¯'able'æˆ–'unable'"
    
    label_value = label_match.group(1).strip()
    
    # æ ¹æ®labelå€¼æ£€æŸ¥ç›¸åº”çš„ç»“æŸæ ‡ç­¾
    if label_value == "able":
        answer_match = re.search(r'<answer>(.*?)</answer>', answer, re.DOTALL)
        if not answer_match:
            return False, "labelä¸º'able'æ—¶ç¼ºå°‘<answer>æ ‡ç­¾"
        
        answer_content = answer_match.group(1).strip()
        if not answer_content:
            return False, "answeræ ‡ç­¾ä¸ºç©º"
            
        # æ£€æŸ¥æ ‡ç­¾é¡ºåºï¼šthink -> label -> answer
        think_pos = think_match.start()
        label_pos = label_match.start()
        answer_pos = answer_match.start()
        
        if not (think_pos < label_pos < answer_pos):
            return False, "æ ‡ç­¾é¡ºåºä¸æ­£ç¡®ï¼Œåº”ä¸º<think>...<label>able</label>...<answer>..."
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸åº”è¯¥å­˜åœ¨çš„<query>æ ‡ç­¾
        query_match = re.search(r'<query>(.*?)</query>', answer, re.DOTALL)
        if query_match:
            return False, "labelä¸º'able'æ—¶ä¸åº”åŒ…å«<query>æ ‡ç­¾"
            
        # æ£€æŸ¥æ˜¯å¦æœ‰æ ‡ç­¾å¤–çš„é¢å¤–æ–‡æœ¬
        clean_text = answer
        clean_text = re.sub(r'<think>.*?</think>', '', clean_text, flags=re.DOTALL)
        clean_text = re.sub(r'<label>\s*able\s*</label>', '', clean_text, flags=re.DOTALL)
        clean_text = re.sub(r'<answer>.*?</answer>', '', clean_text, flags=re.DOTALL)
        clean_text = clean_text.strip()
        
        if clean_text:
            return False, f"åŒ…å«æ ‡ç­¾å¤–çš„é¢å¤–æ–‡æœ¬: {clean_text[:50]}..."
    
    elif label_value == "unable":
        query_match = re.search(r'<query>(.*?)</query>', answer, re.DOTALL)
        if not query_match:
            return False, "labelä¸º'unable'æ—¶ç¼ºå°‘<query>æ ‡ç­¾"
        
        query_content = query_match.group(1).strip()
        if not query_content:
            return False, "queryæ ‡ç­¾ä¸ºç©º"
            
        # æ£€æŸ¥æ ‡ç­¾é¡ºåºï¼šthink -> label -> query
        think_pos = think_match.start()
        label_pos = label_match.start()
        query_pos = query_match.start()
        
        if not (think_pos < label_pos < query_pos):
            return False, "æ ‡ç­¾é¡ºåºä¸æ­£ç¡®ï¼Œåº”ä¸º<think>...<label>unable</label>...<query>..."
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸åº”è¯¥å­˜åœ¨çš„<answer>æ ‡ç­¾
        answer_match = re.search(r'<answer>(.*?)</answer>', answer, re.DOTALL)
        if answer_match:
            return False, "labelä¸º'unable'æ—¶ä¸åº”åŒ…å«<answer>æ ‡ç­¾"
            
        # æ£€æŸ¥æ˜¯å¦æœ‰æ ‡ç­¾å¤–çš„é¢å¤–æ–‡æœ¬
        clean_text = answer
        clean_text = re.sub(r'<think>.*?</think>', '', clean_text, flags=re.DOTALL)
        clean_text = re.sub(r'<label>\s*unable\s*</label>', '', clean_text, flags=re.DOTALL)
        clean_text = re.sub(r'<query>.*?</query>', '', clean_text, flags=re.DOTALL)
        clean_text = clean_text.strip()
        
        if clean_text:
            return False, f"åŒ…å«æ ‡ç­¾å¤–çš„é¢å¤–æ–‡æœ¬: {clean_text[:50]}..."
    
    return True, "æ ¼å¼æ­£ç¡®"


def check_sft_format(answer: str) -> bool:
    """æ£€æŸ¥è¾“å‡ºæ˜¯å¦éµå®ˆSFTæ ¼å¼è§„åˆ™"""
    result, _ = check_sft_format_detailed(answer)
    return result


def log_regenerate(record_id: int, attempt: int, reason: str, log_path: Path):
    """è®°å½•é‡æ–°ç”Ÿæˆçš„ä¿¡æ¯åˆ°æ—¥å¿—æ–‡ä»¶"""
    timestamp = pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')
    log_entry = f"[{timestamp}] è®°å½•ID: {record_id}, é‡è¯•æ¬¡æ•°: {attempt}, åŸå› : {reason}\n"
    
    with open(log_path, 'a', encoding='utf-8') as f:
        f.write(log_entry)


def load_existing_results(output_path: Path):
    """åŠ è½½å·²å­˜åœ¨çš„è¾“å‡º jsonl æ–‡ä»¶ï¼Œè¿”å› (è®°å½•åˆ—è¡¨, å·²å¤„ç†æ•°é‡)"""
    if output_path.exists():
        try:
            df = pd.read_json(output_path, lines=True)
            records = df.to_dict("records")
            return records, len(records)
        except Exception:
            # æ–‡ä»¶æŸåæˆ–é jsonl æ ¼å¼ï¼Œé‡æ–°å¼€å§‹
            pass
    return [], 0


def save_results(records, output_path: Path):
    """ä»¥ jsonl æ ¼å¼ä¿å­˜è®°å½•åˆ—è¡¨"""
    df = pd.DataFrame(records)
    df.to_json(output_path, orient="records", lines=True)


# SFTæ¨ç†promptæ¨¡æ¿
SFT_PROMPT_TEMPLATE = """You are a reasoning assistant working with information from a knowledge graph.

Your task is to answer the user query with the provided graph evidence and your own knowledge.
Follow this process for each query:

1. Carefully read the user query and the retrieved graph evidence.
2. Think step-by-step about what the query is asking and what the evidence supports.
3. Use both the graph evidence and your own knowledge to reason through the query.

- If the evidence **is sufficient**, respond in the following format:
  <think> reasoning here. </think>
  <label> able </label>  
  <answer> final answer here. </answer>

- If the evidence **is not sufficient**, do the following:
  - Identify what key information is missing to answer the query.
  - Propose a natural, specific follow-up question that would help obtain the missing evidence.
  - Respond in the following format:   
  <think> reasoning here. </think>
  <label> unable </label>  
  <query> proposed follow-up question here. </query>

Do not include any text outside the specified tags. Maintain strict adherence to the format.

---

User query: {query}

Graph evidence: 
{context_text}"""


async def process_sft_records(records, start_idx: int = 0, max_concurrent: int = 50, output_path: Path = None, existing_records: list = None):
    """å¤„ç†è®°å½•ï¼Œè°ƒç”¨APIç”ŸæˆSFTè¾“å‡º"""
    llm = LLM()  # ä½¿ç”¨é»˜è®¤é…ç½®çš„ LLM
    all_results = existing_records.copy() if existing_records else []
    dataset_len = len(records)
    regenerate_log_path = Path("regenerate_sft.log")
    
    print(f"ğŸš€ åˆ†æ‰¹å¹¶å‘å¤„ç† {dataset_len} ä¸ªè®°å½•ï¼Œæ¯æ‰¹{max_concurrent}ä¸ª")
    
    # åˆ†æ‰¹å¤„ç†
    for batch_start in range(0, len(records), max_concurrent):
        batch_end = min(batch_start + max_concurrent, len(records))
        batch_records = records[batch_start:batch_end]
        
        print(f"ğŸ“¦ å¤„ç†ç¬¬ {batch_start//max_concurrent + 1} æ‰¹: {batch_start + start_idx + 1} - {batch_end + start_idx}")
        
        # æ¯æ‰¹å†…éƒ¨å¹¶å‘å¤„ç†
        semaphore = asyncio.Semaphore(max_concurrent)
        
        async def _process_single(rec: dict, idx_in_batch: int):
            async with semaphore:
                original_idx = start_idx + batch_start + idx_in_batch
                
                # æ„å»ºpromptï¼Œä½¿ç”¨ç”¨æˆ·æŸ¥è¯¢å’Œå›¾è¯æ®
                query = str(rec.get("query", rec.get("question", "")))
                context_text = str(rec.get("context_text", rec.get("retrieved_context", "")))
                
                prompt = SFT_PROMPT_TEMPLATE.format(
                    query=query,
                    context_text=context_text
                )
                
                max_attempts = 20  # æœ€å¤šé‡è¯•20æ¬¡
                for attempt in range(1, max_attempts + 1):
                    answer = await llm.aask(prompt)
                    
                    is_valid, error_reason = check_sft_format_detailed(answer)
                    if is_valid:
                        # æ ¼å¼æ­£ç¡®ï¼Œè®°å½•å®Œæ•´è¾“å‡º
                        rec["sft_output"] = answer
                        rec["sft_prompt"] = prompt  # è®°å½•å‘é€ç»™å¤§æ¨¡å‹çš„prompt
                        
                        if attempt > 1:
                            print(f"âœ… {original_idx + 1}/{start_idx + dataset_len}: å®Œæˆ (é‡è¯•{attempt-1}æ¬¡åæˆåŠŸ)")
                        else:
                            print(f"âœ… {original_idx + 1}/{start_idx + dataset_len}: å®Œæˆ")
                        return rec
                    else:
                        # æ ¼å¼ä¸æ­£ç¡®ï¼Œè®°å½•è¯¦ç»†æ—¥å¿—
                        reason = f"{error_reason} (ç¬¬{attempt}æ¬¡å°è¯•)"
                        log_regenerate(original_idx, attempt, reason, regenerate_log_path)
                        
                        if attempt < max_attempts:
                            print(f"âš ï¸  {original_idx + 1}/{start_idx + dataset_len}: {error_reason}ï¼Œé‡æ–°ç”Ÿæˆä¸­...")
                        else:
                            print(f"âŒ {original_idx + 1}/{start_idx + dataset_len}: é‡è¯•{max_attempts}æ¬¡åä»ä¸ç¬¦åˆæ ¼å¼ ({error_reason})ï¼Œæ ‡è®°ä¸ºformat wrong")
                            # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ ‡è®°ä¸ºformat wrong
                            rec["sft_output"] = "format wrong"
                            rec["sft_prompt"] = prompt  # å³ä½¿æ ¼å¼ä¸æ­£ç¡®ä¹Ÿè®°å½•prompt
                            return rec
                
                return rec  # ç†è®ºä¸Šä¸ä¼šåˆ°è¾¾è¿™é‡Œ
        
        # æ‰§è¡Œå½“å‰æ‰¹æ¬¡çš„å¹¶å‘æŸ¥è¯¢
        tasks = [_process_single(record, i) for i, record in enumerate(batch_records)]
        batch_results = await asyncio.gather(*tasks)
        
        # å°†å½“å‰æ‰¹æ¬¡ç»“æœåŠ å…¥æ€»ç»“æœ
        all_results.extend(batch_results)
        
        # æ¯æ‰¹å®Œæˆåç«‹å³ä¿å­˜
        if output_path:
            save_results(all_results, output_path)
        
        print(f"ğŸ’¾ ç¬¬ {batch_start//max_concurrent + 1} æ‰¹å®Œæˆï¼Œå·²ä¿å­˜ {len(all_results)} ä¸ªè®°å½•")
    
    return all_results


async def main():
    parser = argparse.ArgumentParser(description='SFTæ•°æ®ç”Ÿæˆå™¨ - åŸºäºå›¾è°±è¯æ®ç”Ÿæˆæ¨ç†è¾“å‡º')
    parser.add_argument('--input', type=str, required=True, help='è¾“å…¥æ–‡ä»¶è·¯å¾„ (json/jsonl)')
    parser.add_argument('--output', type=str, required=True, help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ (jsonl)')
    parser.add_argument('--max_concurrent', type=int, default=50, help='æœ€å¤§å¹¶å‘æ•°')
    
    args = parser.parse_args()
    
    input_path = Path(args.input)
    output_path = Path(args.output)
    max_concurrent = args.max_concurrent

    if not input_path.exists():
        raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ {input_path} ä¸å­˜åœ¨")

    # è¯»å–è¾“å…¥æ•°æ®
    try:
        df_input = pd.read_json(input_path, lines=True)
    except ValueError:
        df_input = pd.read_json(input_path)
    input_records = df_input.to_dict("records")

    print(f"[SFTç”Ÿæˆ] æ€»è®°å½•æ•°: {len(input_records)}")

    # æ£€æŸ¥æ˜¯å¦æœ‰å·²ç”Ÿæˆçš„ç»“æœï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰
    existing_records, processed_cnt = load_existing_results(output_path)
    
    if existing_records:
        # æ‰¾å‡ºå·²å¤„ç†çš„è®°å½•ï¼ˆæœ‰sft_outputå­—æ®µï¼‰
        processed_ids = {rec.get("id") for rec in existing_records if "sft_output" in rec}
        
        # è¿‡æ»¤å‡ºæœªå¤„ç†çš„è®°å½•
        remaining_records = [rec for rec in input_records if rec.get("id") not in processed_ids]
        
        print(f"[SFTç”Ÿæˆ] å·²å¤„ç†è®°å½•: {len(processed_ids)}, å‰©ä½™è®°å½•: {len(remaining_records)}")
        
        if not remaining_records:
            print("[SFTç”Ÿæˆ] æ‰€æœ‰è®°å½•å·²å¤„ç†å®Œæˆï¼Œæ— éœ€é‡æ–°å¤„ç†ã€‚")
            return
    else:
        remaining_records = input_records

    if remaining_records:
        # å¤„ç†å‰©ä½™çš„è®°å½•
        final_results = await process_sft_records(
            remaining_records,
            start_idx=len(existing_records) if existing_records else 0,
            max_concurrent=max_concurrent,
            output_path=output_path,
            existing_records=existing_records
        )
        print(f"âœ… SFTè®°å½•å¤„ç†å®Œæˆï¼å…±å¤„ç† {len(remaining_records)} ä¸ªè®°å½•")
    else:
        print("[SFTç”Ÿæˆ] æ— éœ€å¤„ç†è®°å½•ï¼Œè¾“å‡ºå·²æ˜¯æœ€æ–°ç‰ˆæœ¬ã€‚")

    print(f"[SFTç”Ÿæˆ] ç»“æœå·²ä¿å­˜åˆ° {output_path}")
    print(f"[SFTç”Ÿæˆ] é‡æ–°ç”Ÿæˆæ—¥å¿—å·²ä¿å­˜åˆ° regenerate_sft.log")


if __name__ == "__main__":
    asyncio.run(main())
